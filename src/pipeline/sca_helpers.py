import requests
import pipeline.pipeline as pipeline
import subprocess
import json
import os
from tqdm import tqdm


def download_scantist_bom_detector(repos_dir, url="https://scripts.scantist.com/scantist-bom-detect.jar"):
    """
    Downloads the scantist_bom_detector jar file necessary for running the Scantist SCA CLI.
    :param repos_dir: the path to the temporary folder that stores all of the cloned repositories
    :param url: the url of the scantist bom detector
    :return: A tuple where the first item is a boolean for whether the file was downloaded or not, and the second item
            is the path of the scantist bom detector file
    """
    file_name = url.split("/")[-1]
    file_path = os.path.join(repos_dir, file_name)
    # check if the file exists first
    if os.path.exists(file_path):
        return False, file_path

    r = requests.get(url)
    if r.status_code != 200:
        raise pipeline.HTTPError(r.status_code)

    with open(file_path, 'wb') as output_file:
        output_file.write(r.content)

    return True, file_path


def call_scantist_sca(repo_path, bom_detector_path, serverUrl="http://119.8.181.73:8237/"):
    """
    Triggers a Scantist SCA scan via the CLI and returns the results as a dictionary
    :param repo_path: the path of the repository
    :param bom_detector_path: the path of the scantist bom detector
    :return: a dictionary containing the results generated by the Scantist SCA run
    """
    p = subprocess.run(f"java -jar {bom_detector_path} -working_dir {repo_path} -download_report "
                       f"--debug")
    if p.returncode != 0:
        raise SystemError(p.stderr)

    results_path = os.path.join(repo_path, 'Scantist-Reports.json')
    with open(results_path, 'r') as results_file:
        data = json.loads(results_file.read())

    # os.remove(results_path)

    return data


def generate_node_link_data(dep_tree_data, report_data, max_level=10):
    data = {
        "type": "force",
        "categories": [{"name": "test", "keyword": {}, "base": "test"}],
        "nodes": {},
        "links": []
    }
    licenses = report_data["results"]["licenses"]
    licenses = list(set(x["license_name"] if x["license_name"] is not None else "None" for x in licenses))

    data["categories"] = [{"name": x, "keyword": {}, "base": x} for x in licenses]

    licenses = dict(zip(licenses, list(range(len(licenses)))))

    def recurse(obj, parent=None):
        nonlocal data
        if obj["level"] >= max_level:
            return
        # get the license info
        # dep_license = obj[]

        # add the node to the data
        lib_id = 0
        if obj["artifact_id"] not in data["nodes"]:
            lib_id = len(data["nodes"].keys())
            data["nodes"][obj["artifact_id"]] = {
                "id": lib_id,
                "name": obj["artifact_id"],
                "value": 1 if obj["type"] == "dependency" else 2,
                "category": 0
            }
        else:
            lib_id = data["nodes"][obj["artifact_id"]]["id"]
        # add the link to the data
        if parent is not None:
            data["links"].append({
                "source": data["nodes"][parent["artifact_id"]]["id"],
                "target": lib_id
            })
        if "dependencies" in obj:
            for dep in obj["dependencies"]:
                recurse(dep, obj)

    recurse(dep_tree_data["projects"][0])

    for dep_license in report_data["results"]["licenses"]:
        license_name = dep_license["license_name"]
        if license_name is None:
            license_name = "None"
        if dep_license["library"] is None:
            continue
        data["nodes"][dep_license["library"]]["category"] = licenses[license_name]

    data["nodes"] = list(data["nodes"].values())

    return data


def push_scantist_sca_data_to_mongodb(repo_owner, repo_name, tag_name, data, client):
    """
    Pushes the repository metadata to the mongoDB database
    :param tag_name: the name of the tag, e.g, 'v1.0.1'
    :param repo_owner: the owner of the repository. Eg, 'facebook'
    :param repo_name: the name of the repository. Eg, 'react'
    :param data: the metadata for the repository (python dictionary)
    :param client: the MongoDB client
    :return: None
    """
    db = client['test_db']
    sca_collection = db['sca_data']
    search_dict = {
        "name": repo_name,
        "owner": repo_owner,
        "tag_name": tag_name
    }
    sca_collection.update_one(search_dict, {'$set': data}, upsert=True)


def collect_scantist_sca_data(repos_dir, repo_path):
    # downloading the scantist-bom-detector
    # tqdm.write('checking if the scantist-bom-detector is already downloaded')
    # did_download, bom_detector_path = download_scantist_bom_detector(repos_dir)
    # if did_download:
    #     tqdm.write("Scantist_bom_detector downloaded successfully")
    # else:
    #     tqdm.write("Scantist_bom_detector was found locally")

    # call_scantist_sca(repo_path, bom_detector_path)

    with open(os.path.join(repo_path, "dependency-tree.json"), 'r') as dep_file:
        dep_tree_data = json.loads(dep_file.read())

    with open(os.path.join(repo_path, "Scantist-Reports.json"), 'r') as report_file:
        sca_report_data = json.loads(report_file.read())

    # os.remove(os.path.join(repo_path, "dependency-tree.json"))
    # os.remove(os.path.join(repo_path, "Scantist-Reports.json"))

    node_link_data = generate_node_link_data(dep_tree_data, sca_report_data)
    with open('node_link_data.json', 'w') as file:
        file.write(json.dumps(node_link_data))

    # push_scantist_sca_data_to_mongodb()
